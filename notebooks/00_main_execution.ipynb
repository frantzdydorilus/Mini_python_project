{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af07f84e",
   "metadata": {},
   "source": [
    "# Flux de travail d'Analyse de Données — Projet EduMart\n",
    "\n",
    "Ce notebook est l'**orchestrateur principal** du projet. Il permet d'exécuter l'intégralité du flux de travail de manière automatisée et séquentielle, garantissant que chaque étape bénéficie des données traitées précédemment.\n",
    "\n",
    "### Flux d'Exécution \n",
    "Le pipeline respecte l'ordre méthodologique défini pour le projet :\n",
    "\n",
    "1.  **[01] Audit des données** : Analyse initiale de la qualité des fichiers bruts et détection des anomalies.\n",
    "2.  **[02] Nettoyage** : Traitement des valeurs manquantes, correction des types et suppression des doublons.\n",
    "3.  **[03] Calcul des ICP** : Génération des indicateurs clés de performance (Ventes, Délais, Satisfaction) sur les données propres.\n",
    "4.  **[04] Fusion & Enrichissement** : Jointures finales (Merge) entre les tables pour créer le dataset consolidé `orders_enriched.csv`.\n",
    "\n",
    "\n",
    "### Informations Techniques\n",
    "* **Méthode** : Commande magique `%run` pour un partage du contexte et des variables entre les notebooks.\n",
    "* **Entrées** : Fichiers CSV du dossier `data/raw/`.\n",
    "* **Sorties** : Fichiers traités dans `data/processed/` et résultats finaux dans `results/tables/`.\n",
    "\n",
    "\n",
    "> **Note :** Pour relancer l'ensemble de l'étude, utilisez la fonction **\"Restart & Run All\"** dans le menu Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01521356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# SCRIPT PRINCIPAL D'ORCHESTRATION DU PROJET\n",
    "# =================================================================\n",
    "\n",
    "print(\"Lancement du pipeline de traitement des données...\")\n",
    "\n",
    "# Étape 1 : Audit (Analyse de la qualité des données brutes)\n",
    "print(\"\\n--- Étape 1 : Audit des données ---\")\n",
    "%run \"01_data_audit.ipynb\"\n",
    "\n",
    "# Étape 2 : Nettoyage (Traitement des types, doublons et valeurs manquantes)\n",
    "print(\"\\n--- Étape 2 : Nettoyage des données ---\")\n",
    "%run \"02_data_cleaning.ipynb\"\n",
    "\n",
    "# Étape 3 : ICP (Calcul des indicateurs clés de performance sur données nettoyées)\n",
    "print(\"\\n--- Étape 3 : Calcul des ICP ---\")\n",
    "%run \"03_ICP.ipynb\"\n",
    "\n",
    "# Étape 4 : Merge (Jointures entre les fichiers clients, produits et ventes)\n",
    "print(\"\\n--- Étape 4 : Enrichissement et Fusion des données ---\")\n",
    "%run \"04_merge.ipynb\"\n",
    "\n",
    "print(\"\\n Exécution terminée avec succès !\")\n",
    "print(\"Les fichiers finaux sont disponibles dans les dossiers 'data/processed/' et 'results/tables/'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
